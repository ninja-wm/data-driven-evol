<table>
  <tr>
    <th style="font-family: 'Times New Roman', serif;">Title</th>
    <th style="font-family: 'Times New Roman', serif;">Abstract</th>
   

</tr>
  <tr>
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/95057
    ">Monte Carlo Tree Search based Space Transfer for Black Box Optimization
    <td style="font-family: 'Times New Roman', serif;">Bayesian optimization (BO) is a popular method for computationally expensive black-box optimization (BBO) problems. However, traditional BO methods need to solve new problems from scratch, leading to slow convergence. Recent studies try to extend BO to a transfer learning setup to speed up the optimization, where search space transfer is one of the most promising approaches and has shown impressive performance on many tasks. However, existing search space transfer methods either lack an adaptive mechanism or are not flexible enough, making it difficult to efficiently identify promising search space during the optimization process. In this paper, we propose a search space transfer learning method based on Monte Carlo tree search (MCTS), called MCTS-transfer, to iteratively divide, select, and optimize in a learned subspace. MCTS-transfer can not only provide a well-performing search space for warm-start but also adaptively identify and leverage the information of similar source tasks to reconstruct the search space during the optimization process. Experiments on synthetic functions, real-world problems and hyper-parameter optimization show that MCTS-transfer can demonstrate superior performance compared to other search space transfer methods under different settings.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/94202">Pretrained Optimization Model for Zero-Shot Black Box Optimization
    <td style="font-family: 'Times New Roman', serif;">Zero-shot optimization involves optimizing a target task that was not seen during training, aiming to provide the optimal solution without or with minimal adjustments to the optimizer. It is crucial to ensure reliable and robust performance in various applications. Current optimizers often struggle with zero-shot optimization and require intricate hyperparameter tuning to adapt to new tasks. To address this, we propose a Pretrained Optimization Model (POM) that leverages knowledge gained from optimizing diverse tasks, offering efficient solutions to zero-shot optimization through direct application or fine-tuning with few-shot samples. Evaluation on the BBOB benchmark and two robot control tasks demonstrates that POM outperforms state-of-the-art black-box optimization methods, especially for high-dimensional tasks. Fine-tuning POM with a small number of samples and budget yields significant performance improvements. Moreover, POM demonstrates robust generalization across diverse task distributions, dimensions, population sizes, and optimization horizons.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/93358">Self-Evolution Decoding for Improving Factuality in Large Language Models
    <td style="font-family: 'Times New Roman', serif;">To enhance the reliability and truthfulness of large language models (LLMs), we introduce Self-Evolution Decoding (SED), a novel and elegant decoding strategy that does not rely on external knowledge bases or require additional fine-tuning. Our method, SED, enhances the quality of LLM outputs by optimizing an implicit objective function using the inherent self-evolution of hidden states of LLMs. This approach allows for an ongoing refinement of outputs during inference, akin to further training, thus providing improved accuracy and interpretability over conventional decoding methods. When evaluated on established benchmarks such as TruthfulQA, SED demonstrates a significant improvement—up to a 10\% increase in factual accuracy over traditional methods. These results indicate that SED not only increases the factual accuracy of LLM outputs but also does so without compromising the model's natural language fluency, positioning it as a suitable solution for critical applications requiring high accuracy and reliability.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/93593">Direct Preference-Based Evolutionary Multi-Objective Optimization with Dueling Bandits
    <td style="font-family: 'Times New Roman', serif;">The ultimate goal of multi-objective optimization (MO) is to assist human decision-makers (DMs) in identifying solutions of interest (SOI) that optimally reconcile multiple objectives according to their preferences. Preference-based evolutionary MO (PBEMO) has emerged as a promising framework that progressively approximates SOI by involving human in the optimization-cum-decision-making process. Yet, current PBEMO approaches are prone to be inefficient and misaligned with the DM’s true aspirations, especially when inadvertently exploiting mis-calibrated reward models. This is further exacerbated when considering the stochastic nature of human feedback. This paper proposes a novel framework that navigates MO to SOI by directly leveraging human feedback without being restricted by a predefined reward model nor cumbersome model selection. Specifically, we developed a clustering-based stochastic dueling bandits algorithm that strategically scales well to high-dimensional dueling bandits, and achieves a regret of O(K^2logT), where K is the number of clusters and T is the number of rounds. The learned preferences are then transformed into a unified probabilistic format that can be readily adapted to prevalent EMO algorithms. This also leads to a principled termination criterion that strategically manages human cognitive loads and computational budget. Experiments on 
    48 benchmark test problems, including synthetic problems, RNA inverse design and protein structure prediction, fully demonstrate the effectiveness of our proposed approach.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/96188">Bias Amplification in Language Model Evolution: An Iterated Learning Perspective
    <td style="font-family: 'Times New Roman', serif;">With the widespread adoption of Large Language Models (LLMs), the prevalence of iterative interactions among these models is anticipated to increase. Notably, recent advancements in multi-round on-policy self-improving methods allow LLMs to generate new examples for training subsequent models. At the same time, multi-agent LLM systems, involving automated interactions among agents, are also increasing in prominence. Thus, in both short and long terms, LLMs may actively engage in an evolutionary process. We draw parallels between the behavior of LLMs and the evolution of human culture, as the latter has been extensively studied by cognitive scientists for decades. Our approach involves leveraging Iterated Learning (IL), a Bayesian framework that elucidates how subtle biases are magnified during human cultural evolution, to explain some behaviors of LLMs. This paper outlines key characteristics of agents' behavior in the Bayesian-IL framework, including predictions that are supported by experimental verification with various LLMs. This theoretical framework could help to more effectively predict and guide the evolution of LLMs in desired directions.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/96071">EASI: Evolutionary Adversarial Simulator Identification for Sim-to-Real Transfer
    <td style="font-family: 'Times New Roman', serif;">Reinforcement Learning (RL) controllers have demonstrated remarkable performance in complex robot control tasks. However, the presence of reality gap often leads to poor performance when deploying policies trained in simulation directly onto real robots. Previous sim-to-real algorithms like Domain Randomization (DR) requires domain-specific expertise and suffers from issues such as reduced control performance and high training costs. In this work, we introduce Evolutionary Adversarial Simulator Identification (EASI), a novel approach that combines Generative Adversarial Network (GAN) and Evolutionary Strategy (ES) to address sim-to-real challenges. Specifically, we consider the problem of sim-to-real as a search problem, where ES acts as a generator in adversarial competition with a neural network discriminator, aiming to find physical parameter distributions that make the state transitions between simulation and reality as similar as possible. The discriminator serves as the fitness function, guiding the evolution of the physical parameter distributions. EASI features simplicity, low cost, and high fidelity, enabling the construction of a more realistic simulator with minimal requirements for real-world data, thus aiding in transferring simulated-trained policies to the real world. We demonstrate the performance of EASI in both sim-to-sim and sim-to-real tasks, showing superior performance compared to existing sim-to-real algorithms.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/94244">Discovering Preference Optimization Algorithms with and for Large Language Models
    <td style="font-family: 'Times New Roman', serif;">Offline preference optimization is a key method for enhancing and controlling the quality of Large Language Model (LLM) outputs. Typically, preference optimization is approached as an offline supervised learning task using manually-crafted convex loss functions. While these methods offer theoretical insights, they are inherently constrained by human creativity and the vast search space for optimal loss functions remains largely unexplored. We address this by performing LLM-driven objective discovery to automatically discover new state-of-the-art preference optimization algorithms without expert human intervention. Specifically, we iteratively prompt an LLM to propose and implement new preference optimization loss functions based on previously-evaluated performance metrics. This process leads to the discovery of previously-unknown and performant preference optimization algorithms. From this exploration, we introduce Discovered Preference Optimization (DiscoPOP), a novel algorithm that adaptively blends logistic and exponential losses. Experiments demonstrate the state-of-the-art performance of DiscoPOP and its successful transfer to held-out tasks. We provide code at https://anonymous.4open.science/r/neurips2024_discopop/.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/93536">Wasserstein Distributionally Robust Optimization through the Lens of Structural Causal Models and Individual Fairness
    <td style="font-family: 'Times New Roman', serif;">In recent years, Wasserstein Distributionally Robust Optimization (DRO) has garnered substantial interest for its efficacy in data-driven decision-making under distributional uncertainty. However, limited research has explored the application of DRO to address individual fairness concerns, particularly when considering causal structures and discrete sensitive attributes in learning problems.To address this gap, we first formulate the DRO problem from the perspectives of causality and individual fairness. We then present the DRO dual formulation as an efficient tool to convert the main problem into a more tractable and computationally efficient form. Next, we characterize the closed form of the approximate worst-case loss quantity as a regularizer, eliminating the max-step in the Min-Max DRO problem. We further estimate the regularizer in more general cases and explore the relationship between DRO and classical robust optimization. Finally, by removing the assumption of a known structural causal model, we provide finite sample error bounds when designing DRO with empirical distributions and estimated causal structures to ensure efficiency and robust learning.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/95339">Cost-aware Bayesian optimization via the Pandora's box Gittins index
    <td style="font-family: 'Times New Roman', serif;">Bayesian optimization is a technique for efficiently optimizing unknown functions in a black-box manner. To handle practical settings where gathering data requires use of finite resources, it is desirable to explicitly incorporate function evaluation costs into Bayesian optimization policies. To understand how to do so, we develop a previously-unexplored connection between cost-aware Bayesian optimization and the Pandora's box problem, a decision problem from economics. The Pandora's box problem admits a Bayesian-optimal solution based on an expression called the Gittins index, which can be reinterpreted as an acquisition function. We study the use of this acquisition function for cost-aware Bayesian optimization, and demonstrate empirically that it performs well, particularly in medium-high dimensions. We further show that this performance carries over to classical Bayesian optimization without explicit evaluation costs. Our work constitutes a first step towards integrating techniques from Gittins index theory into Bayesian optimization.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/96598">Minimizing UCB: a Better Local Search Strategy in Local Bayesian Optimization
    <td style="font-family: 'Times New Roman', serif;">Local Bayesian optimization is a promising practical approach to solve the high dimensional black-box function optimization problem. Among them is the approximated gradient class of methods, which implements a strategy similar to gradient descent. These methods have achieved good experimental results and theoretical guarantees. However, given the distributional properties of the Gaussian processes applied on these methods, there may be potential to further exploit the information of the Gaussian processes to facilitate the BO search. In this work, we develop the relationship between the steps of the gradient descent method and one that minimizes the Upper Confidence Bound (UCB), and show that the latter can be a better strategy than direct gradient descent when a Gaussian process is applied as a surrogate. Through this insight, we propose a new local Bayesian optimization algorithm, MinUCB, which replaces the gradient descent step with minimizing UCB in GIBO. We further show that MinUCB maintains a similar convergence rate with GIBO. We then improve the acquisition function of MinUCB further through a look ahead strategy, and obtain a more efficient algorithm LA-MinUCB. We apply our algorithms on different synthetic and real-world functions, and the results show the effectiveness of our method. Our algorithms also illustrate improvements on local search strategies from an upper bound perspective in Bayesian optimization, and provides a new direction for future algorithm design.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/93359">Approximation-Aware Bayesian Optimization
    <td style="font-family: 'Times New Roman', serif;">High-dimensional Bayesian optimization (BO) tasks such as molecular design often require >10,000 function evaluations before obtaining meaningful results. While methods like sparse variational Gaussian processes (SVGPs) reduce computational requirements in these settings, the underlying approximations result in suboptimal data acquisitions that slow the progress of optimization. In this paper we modify SVGPs to better align with the goals of BO: targeting informed data acquisition over global posterior fidelity. Using the framework of utility-calibrated variational inference (Lacoste–Julien et al., 2011), we unify GP approximation and data acquisition into a joint optimization problem, thereby ensuring optimal decisions under a limited computational budget. Our approach can be used with any decision-theoretic acquisition function and is readily compatible with trust region methods like TuRBO (Eriksson et al., 2019). We derive efficient joint objectives for the expected improvement (EI) and knowledge gradient (KG) acquisition functions in both the standard and batch BO settings. On a variety of recent high dimensional benchmark tasks in control and molecular design, our approach significantly outperforms standard SVGPs and is capable of achieving comparable rewards with up to 10 × fewer function evaluations
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/93860">Acceleration Exists! Optimization Problems When Oracle Can Only Compare Objective Function Values
    <td style="font-family: 'Times New Roman', serif;">Frequently, the burgeoning field of black-box optimization encounters challenges due to a limited understanding of the mechanisms of the objective function. To address such problems, in this work we focus on the deterministic concept of Order Oracle, which only utilizes order access between function values (possibly with some bounded noise), but without assuming access to their values. As theoretical results, we propose a new approach to create non-accelerated optimization algorithms (obtained by integrating Order Oracle into existing optimization “tools”) in non-convex, convex, and strongly convex settings that are as good as both SOTA coordinate algorithms with first-order oracle and SOTA algorithms with Order Oracle up to logarithm factor. Moreover, using the proposed approach, we provide the first accelerated optimization algorithm using the Order Oracle. And also, using an already different approach we provide the asymptotic convergence of the first algorithm with the stochastic Order Oracle concept. Finally, our theoretical results demonstrate effectiveness of proposed algorithms through numerical experiments.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/96744">Generative Adversarial Bayesian Optimization for Surrogate Objectives
    <td style="font-family: 'Times New Roman', serif;">Offline model-based policy optimization seeks to optimize against a learned surrogate model without querying the true oracle objective function during optimization. However, inaccurate surrogate model predictions are frequently encountered along the optimization trajectory. To address this limitation, we propose generative adversarial Bayesian optimization (GABO) using adaptive source critic regularization, a task-agnostic framework for Bayesian optimization that employs a Lipschitz-bounded source critic model to constrain the optimization trajectory to regions where the surrogate function is reliable. We show that under certain assumptions for the continuous input space prior, our algorithm can dynamically adjust the strength of the source critic regularization. GABO outperforms existing baselines on a number of different offline optimization tasks across a variety of scientific domains.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/94068">Localized Zeroth-Order Prompt Optimization
    <td style="font-family: 'Times New Roman', serif;">The efficacy of large language models (LLMs) in understanding and generating natural language has aroused a wide interest in developing prompt-based methods to harness the power of black-box LLMs. Existing methodologies usually prioritize a global optimization for finding the global optimum, which however will perform poorly in certain tasks. This thus motivates us to re-think the necessity of finding a global optimum in prompt optimization. To answer this, we conduct a thorough empirical study on prompt optimization and draw two major insights. Contrasting with the rarity of global optimum, local optima are usually prevalent and well-performed, which can be more worthwhile for efficient prompt optimization (Insight I). The choice of the input domain, covering both the generation and the representation of prompts, affects the identification of well-performing local optima (Insight II). Inspired by these insights, we propose a novel algorithm, namely localized zeroth-order prompt optimization (ZOPO), which incorporates a Neural Tangent Kernel-based derived Gaussian process into standard zeroth-order optimization for an efficient search of well-performing local optima in prompt optimization. Remarkably, ZOPO outperforms existing baselines in terms of both the optimization performance and the query efficiency, which we demonstrate through extensive experiments.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/95631">Bayesian Optimization of Functions over Node Subsets in Graphs
    <td style="font-family: 'Times New Roman', serif;">We address the problem of optimizing over functions defined on node subsets in a graph. The optimization of such functions is often a non-trivial task given their combinatorial, black-box and expensive-to-evaluate nature. Although various algorithms have been introduced in the literature, most are either task-specific or computationally inefficient and only utilize information about the graph structure without considering the characteristics of the function. To address these limitations, we utilize Bayesian Optimization (BO), a sample-efficient black-box solver, and propose a novel framework for combinatorial optimization on graphs. More specifically, we map each k-node subset in the original graph to a node in a new combinatorial graph and adopt a local modeling approach to efficiently traverse the latter graph by progressively sampling its subgraphs using a recursive algorithm. Extensive experiments under both synthetic and real-world setups demonstrate the effectiveness of the proposed BO framework on various types of graphs and optimization tasks, where its behavior is analyzed in detail with ablation studies.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/96692">Large Language Models as Hyper-Heuristics for Combinatorial Optimization
    <td style="font-family: 'Times New Roman', serif;">The omnipresence of NP-hard combinatorial optimization problems (COPs) compels domain experts to engage in trial-and-error heuristic design. The long-standing endeavor of design automation has gained new momentum with the rise of large language models (LLMs). This paper introduces Language Hyper-Heuristics (LHHs), an emerging variant of Hyper-Heuristics that leverages LLMs for heuristic generation, featuring minimal manual intervention and open-ended heuristic spaces. To empower LHHs, we present Reflective Evolution (ReEvo), a novel integration of evolutionary search for efficiently exploring the heuristic space, and LLM reflections to provide verbal gradients within the space. Across five heterogeneous algorithmic types, six different COPs, and both white-box and black-box views of COPs, ReEvo yields state-of-the-art and competitive meta-heuristics, evolutionary algorithms, heuristics, and neural solvers, while being more sample-efficient than prior LHHs.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/93989">Guided Trajectory Generation with Diffusion Models for Offline Model-based Optimization
    <td style="font-family: 'Times New Roman', serif;">Optimizing complex and high-dimensional black-box functions is ubiquitous in science and engineering fields. Unfortunately, the online evaluation of these functions is restricted due to time and safety constraints in most cases. In offline model-based optimization (MBO), we aim to find a design that maximizes the target function using only a pre-existing offline dataset. While prior methods consider forward or inverse approaches to address the problem, these approaches are limited by conservatism and the difficulty of learning highly multi-modal mappings. Recently, there has been an emerging paradigm of learning to improve solutions with synthetic trajectories constructed from the offline dataset. In this paper, we introduce a novel conditional generative modeling approach to produce trajectories toward high-scoring regions. First, we construct synthetic trajectories toward high-scoring regions using the dataset while injecting locality bias for consistent improvement directions. Then, we train a conditional diffusion model to generate trajectories conditioned on their scores. Lastly, we sample multiple trajectories from the trained model with guidance to explore high-scoring regions beyond the dataset and select high-fidelity designs among generated trajectories with the proxy function. Extensive experiment results demonstrate that our method outperforms competitive baselines on Design-Bench and its practical variants. The code is publicly available in https://anonymous.4open.science/r/GTG-0D03/.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/95382">Scalable Bayesian Optimization via Focalized Sparse Gaussian Processes
    <td style="font-family: 'Times New Roman', serif;">Bayesian optimization is an effective technique for black-box optimization, but its applicability is typically limited to low-dimensional and small-budget problems due to the cubic complexity of computing the Gaussian process (GP) surrogate. While various approximate GP models have been employed to scale Bayesian optimization to larger sample sizes, most suffer from overly-smooth estimation and focus primarily on problems that allow for large online samples. In this work, we argue that Bayesian optimization algorithms with sparse GPs can more efficiently allocate their representational power to relevant regions of the search space. To achieve this, we propose focalized GP, which leverages a novel variational loss function to achieve stronger local prediction, as well as FocalBO, which hierarchically optimizes the focalized GP acquisition function over progressively smaller search spaces. Experimental results demonstrate that FocalBO can efficiently leverage large amounts of offline and online data to achieve state-of-the-art performance on robot morphology design and to control a 585-dimensional musculoskeletal system.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/94288">Transition Constrained Bayesian Optimization via Markov Decision Processes
    <td style="font-family: 'Times New Roman', serif;">Bayesian optimization is a methodology to optimize black-box functions. Traditionally, it focuses on the setting where you can arbitrarily query the search space. However, many real-life problems do not offer this flexibility; in particular, the search space of the next query may depend on previous ones. Example challenges arise in the physical sciences in the form of local movement constraints, required monotonicity in certain variables, and transitions influencing the accuracy of measurements. Altogether, such transition constraints necessitate a form of planning. This work extends classical Bayesian optimization via the framework of Markov Decision Processes. We iteratively solve a tractable linearization of our utility function using reinforcement learning to obtain a policy that plans ahead for the entire horizon. This is a parallel to the optimization of an acquisition function in policy space. The resulting policy is potentially history-dependent and non-Markovian. We showcase applications in chemical reactor optimization, informative path planning, machine calibration, and other synthetic examples.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/93900">This Too Shall Pass: Removing Stale Observations in Dynamic Bayesian Optimization
    <td style="font-family: 'Times New Roman', serif;"> Bayesian Optimization (BO) has proven to be very successful at optimizing a static, noisy, costly-to-evaluate black-box function f:S→R. However, optimizing a black-box which is also a function of time (*i.e.*, a *dynamic* function) f:S×T→Rremains a challenge, since a dynamic Bayesian Optimization (DBO) algorithm has to keep track of the optimum over time. This changes the nature of the optimization problem in at least three aspects: (i) querying an arbitrary point in S×T is impossible, (ii) past observations become less and less relevant for keeping track of the optimum as time goes by and (iii) the DBO algorithm must have a high sampling frequency so it can collect enough relevant observations to keep track of the optimum through time. In this paper, we design a Wasserstein distance-based criterion able to quantify the relevancy of an observation with respect to future predictions. Then, we leverage this criterion to build W-DBO, a DBO algorithm able to remove irrelevant observations from its dataset on the fly, thus maintaining simultaneously a good predictive performance and a high sampling frequency, even in continuous-time optimization tasks with unknown horizon. Numerical experiments establish the superiority of W-DBO, which outperforms state-of-the-art methods by a comfortable margin.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/92981">ReLIZO: Sample Reusable Linear Interpolation-based Zeroth-order Optimization
    <td style="font-family: 'Times New Roman', serif;">Gradient estimation is critical in zeroth-order optimization methods, which aims to obtain the descent direction by sampling update directions and querying function evaluations. Extensive research has been conducted including smoothing and linear interpolation. The former methods smooth the objective function, causing a biased gradient estimation, while the latter often enjoys more accurate estimates, at the cost of large amounts of samples and queries at each iteration to update variables. This paper resorts to the linear interpolation strategy and proposes to reduce the complexity of gradient estimation by reusing queries in the prior iterations while maintaining the sample size unchanged. Specifically, we model the gradient estimation as a quadratically constrained linear program problem and manage to derive the analytical solution. It innovatively decouples the required sample size from the variable dimension without extra conditions required, making it able to leverage the queries in the prior iterations. Moreover, part of the intermediate variables that contribute to the gradient estimation can be directly indexed, significantly reducing the computation complexity. Experiments on both simulation functions and real scenarios (black-box adversarial attacks and neural architecture search), show its efficacy and efficiency.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/97688">A survey and benchmark of high-dimensional Bayesian optimization of discrete sequences
    <td style="font-family: 'Times New Roman', serif;">Optimizing discrete black-box functions is key in several domains, e.g. protein engineering and drug design. Due to the lack of gradient information and the need for sample efficiency, Bayesian optimization is an ideal candidate for these tasks. Several methods for high-dimensional continuous and categorical Bayesian optimization have been proposed recently. However, our survey of the field reveals highly heterogeneous experimental set-ups across methods and technical barriers for the replicability and application of published algorithms to real-world tasks. To address these issues, we develop a unified framework to test a vast array of high-dimensional Bayesian optimization methods and a collection of standardized black-box functions representing real-world application domains in chemistry and biology. These two components of the benchmark are each supported by flexible, scalable, and easily extendable software libraries (poli and poli-baselines), allowing practitioners to readily incorporate new optimization objectives or discrete optimizers. Project website: https://machinelearninglifescience.github.io/hdbo_benchmark.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="https://neurips.cc/virtual/2024/poster/93157">Batched Energy-Entropy acquisition for Bayesian Optimization
    <td style="font-family: 'Times New Roman', serif;">Bayesian optimization (BO) is an attractive machine learning framework for performing sample-efficient global optimization of black-box functions. The optimization process is guided by an acquisition function that selects points to acquire in each round of BO. In batched BO, when multiple points are acquired in parallel, commonly used acquisition functions are often high-dimensional and intractable, leading to the use of sampling-based alternatives. We propose a statistical physics inspired acquisition function that can natively handle batches. Batched Energy-Entropy acquisition for BO (BEEBO) enables tight control of the explore-exploit trade-off of the optimization process and generalizes to heteroskedastic black-box problems. We demonstrate the applicability of BEEBO on a range of problems, showing competitive performance to existing acquisition functions.
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="">
    <td style="font-family: 'Times New Roman', serif;">
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="">
    <td style="font-family: 'Times New Roman', serif;">
</tr>
  <tr>    
    <td style="font-family: 'Times New Roman', serif; font-weight: bold;"><a href="">
    <td style="font-family: 'Times New Roman', serif;">

  </tr>
</table>
